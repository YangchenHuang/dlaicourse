{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Course 3 - Week 4 - Lesson 1 - Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YangchenHuang/dlaicourse/blob/master/TensorFlow%20In%20Practice/Course%203%20-%20NLP/Course%203%20-%20Week%204%20-%20Lesson%201%20-%20Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOwsuGQQY9OL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "e8928bae-079d-4a10-9f58-b30b269c495f"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PRnDnCW-Z7qv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "479a6917-6968-45b2-d288-bfba9585d7af"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "data=\"In the town of Athy one Jeremy Lanigan \\n Battered away til he hadnt a pound. \\nHis father died and made him a man again \\n Left him a farm and ten acres of ground. \\nHe gave a grand party for friends and relations \\nWho didnt forget him when come to the wall, \\nAnd if youll but listen Ill make your eyes glisten \\nOf the rows and the ructions of Lanigans Ball. \\nMyself to be sure got free invitation, \\nFor all the nice girls and boys I might ask, \\nAnd just in a minute both friends and relations \\nWere dancing round merry as bees round a cask. \\nJudy ODaly, that nice little milliner, \\nShe tipped me a wink for to give her a call, \\nAnd I soon arrived with Peggy McGilligan \\nJust in time for Lanigans Ball. \\nThere were lashings of punch and wine for the ladies, \\nPotatoes and cakes; there was bacon and tea, \\nThere were the Nolans, Dolans, OGradys \\nCourting the girls and dancing away. \\nSongs they went round as plenty as water, \\nThe harp that once sounded in Taras old hall,\\nSweet Nelly Gray and The Rat Catchers Daughter,\\nAll singing together at Lanigans Ball. \\nThey were doing all kinds of nonsensical polkas \\nAll round the room in a whirligig. \\nJulia and I, we banished their nonsense \\nAnd tipped them the twist of a reel and a jig. \\nAch mavrone, how the girls got all mad at me \\nDanced til youd think the ceiling would fall. \\nFor I spent three weeks at Brooks Academy \\nLearning new steps for Lanigans Ball. \\nThree long weeks I spent up in Dublin, \\nThree long weeks to learn nothing at all,\\n Three long weeks I spent up in Dublin, \\nLearning new steps for Lanigans Ball. \\nShe stepped out and I stepped in again, \\nI stepped out and she stepped in again, \\nShe stepped out and I stepped in again, \\nLearning new steps for Lanigans Ball. \\nBoys were all merry and the girls they were hearty \\nAnd danced all around in couples and groups, \\nTil an accident happened, young Terrance McCarthy \\nPut his right leg through miss Finnertys hoops. \\nPoor creature fainted and cried Meelia murther, \\nCalled for her brothers and gathered them all. \\nCarmody swore that hed go no further \\nTil he had satisfaction at Lanigans Ball. \\nIn the midst of the row miss Kerrigan fainted, \\nHer cheeks at the same time as red as a rose. \\nSome of the lads declared she was painted, \\nShe took a small drop too much, I suppose. \\nHer sweetheart, Ned Morgan, so powerful and able, \\nWhen he saw his fair colleen stretched out by the wall, \\nTore the left leg from under the table \\nAnd smashed all the Chaneys at Lanigans Ball. \\nBoys, oh boys, twas then there were runctions. \\nMyself got a lick from big Phelim McHugh. \\nI soon replied to his introduction \\nAnd kicked up a terrible hullabaloo. \\nOld Casey, the piper, was near being strangled. \\nThey squeezed up his pipes, bellows, chanters and all. \\nThe girls, in their ribbons, they got all entangled \\nAnd that put an end to Lanigans Ball.\"\n",
        "\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(total_words)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'and': 1, 'the': 2, 'a': 3, 'in': 4, 'all': 5, 'i': 6, 'for': 7, 'of': 8, 'lanigans': 9, 'ball': 10, 'were': 11, 'at': 12, 'to': 13, 'she': 14, 'stepped': 15, 'his': 16, 'girls': 17, 'as': 18, 'they': 19, 'til': 20, 'he': 21, 'again': 22, 'got': 23, 'boys': 24, 'round': 25, 'that': 26, 'her': 27, 'there': 28, 'three': 29, 'weeks': 30, 'up': 31, 'out': 32, 'him': 33, 'was': 34, 'spent': 35, 'learning': 36, 'new': 37, 'steps': 38, 'long': 39, 'away': 40, 'left': 41, 'friends': 42, 'relations': 43, 'when': 44, 'wall': 45, 'myself': 46, 'nice': 47, 'just': 48, 'dancing': 49, 'merry': 50, 'tipped': 51, 'me': 52, 'soon': 53, 'time': 54, 'old': 55, 'their': 56, 'them': 57, 'danced': 58, 'dublin': 59, 'an': 60, 'put': 61, 'leg': 62, 'miss': 63, 'fainted': 64, 'from': 65, 'town': 66, 'athy': 67, 'one': 68, 'jeremy': 69, 'lanigan': 70, 'battered': 71, 'hadnt': 72, 'pound': 73, 'father': 74, 'died': 75, 'made': 76, 'man': 77, 'farm': 78, 'ten': 79, 'acres': 80, 'ground': 81, 'gave': 82, 'grand': 83, 'party': 84, 'who': 85, 'didnt': 86, 'forget': 87, 'come': 88, 'if': 89, 'youll': 90, 'but': 91, 'listen': 92, 'ill': 93, 'make': 94, 'your': 95, 'eyes': 96, 'glisten': 97, 'rows': 98, 'ructions': 99, 'be': 100, 'sure': 101, 'free': 102, 'invitation': 103, 'might': 104, 'ask': 105, 'minute': 106, 'both': 107, 'bees': 108, 'cask': 109, 'judy': 110, 'odaly': 111, 'little': 112, 'milliner': 113, 'wink': 114, 'give': 115, 'call': 116, 'arrived': 117, 'with': 118, 'peggy': 119, 'mcgilligan': 120, 'lashings': 121, 'punch': 122, 'wine': 123, 'ladies': 124, 'potatoes': 125, 'cakes': 126, 'bacon': 127, 'tea': 128, 'nolans': 129, 'dolans': 130, 'ogradys': 131, 'courting': 132, 'songs': 133, 'went': 134, 'plenty': 135, 'water': 136, 'harp': 137, 'once': 138, 'sounded': 139, 'taras': 140, 'hall': 141, 'sweet': 142, 'nelly': 143, 'gray': 144, 'rat': 145, 'catchers': 146, 'daughter': 147, 'singing': 148, 'together': 149, 'doing': 150, 'kinds': 151, 'nonsensical': 152, 'polkas': 153, 'room': 154, 'whirligig': 155, 'julia': 156, 'we': 157, 'banished': 158, 'nonsense': 159, 'twist': 160, 'reel': 161, 'jig': 162, 'ach': 163, 'mavrone': 164, 'how': 165, 'mad': 166, 'youd': 167, 'think': 168, 'ceiling': 169, 'would': 170, 'fall': 171, 'brooks': 172, 'academy': 173, 'learn': 174, 'nothing': 175, 'hearty': 176, 'around': 177, 'couples': 178, 'groups': 179, 'accident': 180, 'happened': 181, 'young': 182, 'terrance': 183, 'mccarthy': 184, 'right': 185, 'through': 186, 'finnertys': 187, 'hoops': 188, 'poor': 189, 'creature': 190, 'cried': 191, 'meelia': 192, 'murther': 193, 'called': 194, 'brothers': 195, 'gathered': 196, 'carmody': 197, 'swore': 198, 'hed': 199, 'go': 200, 'no': 201, 'further': 202, 'had': 203, 'satisfaction': 204, 'midst': 205, 'row': 206, 'kerrigan': 207, 'cheeks': 208, 'same': 209, 'red': 210, 'rose': 211, 'some': 212, 'lads': 213, 'declared': 214, 'painted': 215, 'took': 216, 'small': 217, 'drop': 218, 'too': 219, 'much': 220, 'suppose': 221, 'sweetheart': 222, 'ned': 223, 'morgan': 224, 'so': 225, 'powerful': 226, 'able': 227, 'saw': 228, 'fair': 229, 'colleen': 230, 'stretched': 231, 'by': 232, 'tore': 233, 'under': 234, 'table': 235, 'smashed': 236, 'chaneys': 237, 'oh': 238, 'twas': 239, 'then': 240, 'runctions': 241, 'lick': 242, 'big': 243, 'phelim': 244, 'mchugh': 245, 'replied': 246, 'introduction': 247, 'kicked': 248, 'terrible': 249, 'hullabaloo': 250, 'casey': 251, 'piper': 252, 'near': 253, 'being': 254, 'strangled': 255, 'squeezed': 256, 'pipes': 257, 'bellows': 258, 'chanters': 259, 'ribbons': 260, 'entangled': 261, 'end': 262}\n",
            "263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soPGVheskaQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJtwVB2NbOAP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "5308b182-01e7-4aa0-c2e2-16ec604268be"
      },
      "source": [
        "print(tokenizer.word_index['in'])\n",
        "print(tokenizer.word_index['the'])\n",
        "print(tokenizer.word_index['town'])\n",
        "print(tokenizer.word_index['of'])\n",
        "print(tokenizer.word_index['athy'])\n",
        "print(tokenizer.word_index['one'])\n",
        "print(tokenizer.word_index['jeremy'])\n",
        "print(tokenizer.word_index['lanigan'])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "2\n",
            "66\n",
            "8\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49Cv68JOakwv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "89f3cd5a-59c8-43db-feb7-a735d4f0c9e5"
      },
      "source": [
        "print(xs[6])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  0  0  4  2 66  8 67 68 69]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY-jwvfgbEF8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "04a4fc9b-0559-4020-a195-c773ad92c9d5"
      },
      "source": [
        "print(ys[6])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtzlUMYadhKt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "48053e21-def6-40da-a50c-4048c6b496e5"
      },
      "source": [
        "print(xs[5])\n",
        "print(ys[5])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  0  0  0  4  2 66  8 67 68]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4myRpB1c4Gg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b6b9a97b-cd34-4eef-ce72-0e9467b7e357"
      },
      "source": [
        "print(tokenizer.word_index)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'and': 1, 'the': 2, 'a': 3, 'in': 4, 'all': 5, 'i': 6, 'for': 7, 'of': 8, 'lanigans': 9, 'ball': 10, 'were': 11, 'at': 12, 'to': 13, 'she': 14, 'stepped': 15, 'his': 16, 'girls': 17, 'as': 18, 'they': 19, 'til': 20, 'he': 21, 'again': 22, 'got': 23, 'boys': 24, 'round': 25, 'that': 26, 'her': 27, 'there': 28, 'three': 29, 'weeks': 30, 'up': 31, 'out': 32, 'him': 33, 'was': 34, 'spent': 35, 'learning': 36, 'new': 37, 'steps': 38, 'long': 39, 'away': 40, 'left': 41, 'friends': 42, 'relations': 43, 'when': 44, 'wall': 45, 'myself': 46, 'nice': 47, 'just': 48, 'dancing': 49, 'merry': 50, 'tipped': 51, 'me': 52, 'soon': 53, 'time': 54, 'old': 55, 'their': 56, 'them': 57, 'danced': 58, 'dublin': 59, 'an': 60, 'put': 61, 'leg': 62, 'miss': 63, 'fainted': 64, 'from': 65, 'town': 66, 'athy': 67, 'one': 68, 'jeremy': 69, 'lanigan': 70, 'battered': 71, 'hadnt': 72, 'pound': 73, 'father': 74, 'died': 75, 'made': 76, 'man': 77, 'farm': 78, 'ten': 79, 'acres': 80, 'ground': 81, 'gave': 82, 'grand': 83, 'party': 84, 'who': 85, 'didnt': 86, 'forget': 87, 'come': 88, 'if': 89, 'youll': 90, 'but': 91, 'listen': 92, 'ill': 93, 'make': 94, 'your': 95, 'eyes': 96, 'glisten': 97, 'rows': 98, 'ructions': 99, 'be': 100, 'sure': 101, 'free': 102, 'invitation': 103, 'might': 104, 'ask': 105, 'minute': 106, 'both': 107, 'bees': 108, 'cask': 109, 'judy': 110, 'odaly': 111, 'little': 112, 'milliner': 113, 'wink': 114, 'give': 115, 'call': 116, 'arrived': 117, 'with': 118, 'peggy': 119, 'mcgilligan': 120, 'lashings': 121, 'punch': 122, 'wine': 123, 'ladies': 124, 'potatoes': 125, 'cakes': 126, 'bacon': 127, 'tea': 128, 'nolans': 129, 'dolans': 130, 'ogradys': 131, 'courting': 132, 'songs': 133, 'went': 134, 'plenty': 135, 'water': 136, 'harp': 137, 'once': 138, 'sounded': 139, 'taras': 140, 'hall': 141, 'sweet': 142, 'nelly': 143, 'gray': 144, 'rat': 145, 'catchers': 146, 'daughter': 147, 'singing': 148, 'together': 149, 'doing': 150, 'kinds': 151, 'nonsensical': 152, 'polkas': 153, 'room': 154, 'whirligig': 155, 'julia': 156, 'we': 157, 'banished': 158, 'nonsense': 159, 'twist': 160, 'reel': 161, 'jig': 162, 'ach': 163, 'mavrone': 164, 'how': 165, 'mad': 166, 'youd': 167, 'think': 168, 'ceiling': 169, 'would': 170, 'fall': 171, 'brooks': 172, 'academy': 173, 'learn': 174, 'nothing': 175, 'hearty': 176, 'around': 177, 'couples': 178, 'groups': 179, 'accident': 180, 'happened': 181, 'young': 182, 'terrance': 183, 'mccarthy': 184, 'right': 185, 'through': 186, 'finnertys': 187, 'hoops': 188, 'poor': 189, 'creature': 190, 'cried': 191, 'meelia': 192, 'murther': 193, 'called': 194, 'brothers': 195, 'gathered': 196, 'carmody': 197, 'swore': 198, 'hed': 199, 'go': 200, 'no': 201, 'further': 202, 'had': 203, 'satisfaction': 204, 'midst': 205, 'row': 206, 'kerrigan': 207, 'cheeks': 208, 'same': 209, 'red': 210, 'rose': 211, 'some': 212, 'lads': 213, 'declared': 214, 'painted': 215, 'took': 216, 'small': 217, 'drop': 218, 'too': 219, 'much': 220, 'suppose': 221, 'sweetheart': 222, 'ned': 223, 'morgan': 224, 'so': 225, 'powerful': 226, 'able': 227, 'saw': 228, 'fair': 229, 'colleen': 230, 'stretched': 231, 'by': 232, 'tore': 233, 'under': 234, 'table': 235, 'smashed': 236, 'chaneys': 237, 'oh': 238, 'twas': 239, 'then': 240, 'runctions': 241, 'lick': 242, 'big': 243, 'phelim': 244, 'mchugh': 245, 'replied': 246, 'introduction': 247, 'kicked': 248, 'terrible': 249, 'hullabaloo': 250, 'casey': 251, 'piper': 252, 'near': 253, 'being': 254, 'strangled': 255, 'squeezed': 256, 'pipes': 257, 'bellows': 258, 'chanters': 259, 'ribbons': 260, 'entangled': 261, 'end': 262}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9vH8Y59ajYL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "41916c44-81b1-4f34-b8bd-7e437c51be89"
      },
      "source": [
        "  model = Sequential()\n",
        "  model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "  model.add(Bidirectional(LSTM(20)))\n",
        "  model.add(Dense(total_words, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  history = model.fit(xs, ys, epochs=500, verbose=1)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 453 samples\n",
            "Epoch 1/500\n",
            "453/453 [==============================] - 2s 5ms/sample - loss: 5.5696 - acc: 0.0155\n",
            "Epoch 2/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 5.5507 - acc: 0.0684\n",
            "Epoch 3/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 5.5127 - acc: 0.0508\n",
            "Epoch 4/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 5.3970 - acc: 0.0508\n",
            "Epoch 5/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 5.1616 - acc: 0.0552\n",
            "Epoch 6/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 5.0753 - acc: 0.0618\n",
            "Epoch 7/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 5.0305 - acc: 0.0530\n",
            "Epoch 8/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.9982 - acc: 0.0530\n",
            "Epoch 9/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.9617 - acc: 0.0574\n",
            "Epoch 10/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.9249 - acc: 0.0773\n",
            "Epoch 11/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.8734 - acc: 0.0662\n",
            "Epoch 12/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.8221 - acc: 0.0640\n",
            "Epoch 13/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.7644 - acc: 0.0684\n",
            "Epoch 14/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.6946 - acc: 0.0773\n",
            "Epoch 15/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.6320 - acc: 0.0706\n",
            "Epoch 16/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.5808 - acc: 0.0817\n",
            "Epoch 17/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.5199 - acc: 0.0861\n",
            "Epoch 18/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.4554 - acc: 0.0927\n",
            "Epoch 19/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.4067 - acc: 0.1104\n",
            "Epoch 20/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.3537 - acc: 0.1148\n",
            "Epoch 21/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.3011 - acc: 0.1082\n",
            "Epoch 22/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.2479 - acc: 0.1192\n",
            "Epoch 23/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.1968 - acc: 0.1148\n",
            "Epoch 24/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.1495 - acc: 0.1258\n",
            "Epoch 25/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.1079 - acc: 0.1413\n",
            "Epoch 26/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.0557 - acc: 0.1325\n",
            "Epoch 27/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.0004 - acc: 0.1457\n",
            "Epoch 28/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.9619 - acc: 0.1678\n",
            "Epoch 29/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.9161 - acc: 0.1722\n",
            "Epoch 30/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.8644 - acc: 0.1943\n",
            "Epoch 31/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.8160 - acc: 0.1965\n",
            "Epoch 32/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.7682 - acc: 0.1921\n",
            "Epoch 33/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.7185 - acc: 0.2053\n",
            "Epoch 34/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.6828 - acc: 0.2097\n",
            "Epoch 35/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.6364 - acc: 0.2230\n",
            "Epoch 36/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.5969 - acc: 0.2296\n",
            "Epoch 37/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.5473 - acc: 0.2406\n",
            "Epoch 38/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.4933 - acc: 0.2649\n",
            "Epoch 39/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.4458 - acc: 0.2759\n",
            "Epoch 40/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.3981 - acc: 0.2715\n",
            "Epoch 41/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.3786 - acc: 0.2804\n",
            "Epoch 42/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.3706 - acc: 0.2715\n",
            "Epoch 43/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.3101 - acc: 0.3046\n",
            "Epoch 44/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.2492 - acc: 0.3267\n",
            "Epoch 45/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.2091 - acc: 0.3488\n",
            "Epoch 46/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.1566 - acc: 0.3466\n",
            "Epoch 47/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.1233 - acc: 0.3510\n",
            "Epoch 48/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.0724 - acc: 0.3841\n",
            "Epoch 49/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.0286 - acc: 0.3753\n",
            "Epoch 50/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.9957 - acc: 0.3841\n",
            "Epoch 51/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.9543 - acc: 0.4018\n",
            "Epoch 52/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.9211 - acc: 0.3885\n",
            "Epoch 53/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.8854 - acc: 0.4084\n",
            "Epoch 54/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.8583 - acc: 0.3974\n",
            "Epoch 55/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.8236 - acc: 0.4150\n",
            "Epoch 56/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.7844 - acc: 0.4238\n",
            "Epoch 57/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.7634 - acc: 0.4305\n",
            "Epoch 58/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.7765 - acc: 0.4327\n",
            "Epoch 59/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.7881 - acc: 0.4349\n",
            "Epoch 60/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.7143 - acc: 0.4393\n",
            "Epoch 61/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.6633 - acc: 0.4525\n",
            "Epoch 62/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.6242 - acc: 0.4614\n",
            "Epoch 63/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.5729 - acc: 0.4812\n",
            "Epoch 64/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.5431 - acc: 0.4879\n",
            "Epoch 65/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.5148 - acc: 0.4746\n",
            "Epoch 66/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.5013 - acc: 0.5055\n",
            "Epoch 67/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.4832 - acc: 0.4857\n",
            "Epoch 68/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.4591 - acc: 0.4812\n",
            "Epoch 69/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.4195 - acc: 0.5166\n",
            "Epoch 70/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.3982 - acc: 0.5188\n",
            "Epoch 71/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.3605 - acc: 0.5408\n",
            "Epoch 72/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.3210 - acc: 0.5408\n",
            "Epoch 73/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.2968 - acc: 0.5430\n",
            "Epoch 74/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.2716 - acc: 0.5673\n",
            "Epoch 75/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.2405 - acc: 0.5717\n",
            "Epoch 76/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.2180 - acc: 0.5894\n",
            "Epoch 77/500\n",
            "453/453 [==============================] - 1s 2ms/sample - loss: 2.1895 - acc: 0.5762\n",
            "Epoch 78/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.1690 - acc: 0.6026\n",
            "Epoch 79/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.1408 - acc: 0.5982\n",
            "Epoch 80/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.1230 - acc: 0.6049\n",
            "Epoch 81/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.0997 - acc: 0.6159\n",
            "Epoch 82/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.0732 - acc: 0.6247\n",
            "Epoch 83/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.0458 - acc: 0.6424\n",
            "Epoch 84/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.0245 - acc: 0.6424\n",
            "Epoch 85/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.0036 - acc: 0.6446\n",
            "Epoch 86/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.9797 - acc: 0.6490\n",
            "Epoch 87/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.9533 - acc: 0.6468\n",
            "Epoch 88/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.9323 - acc: 0.6534\n",
            "Epoch 89/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.9125 - acc: 0.6689\n",
            "Epoch 90/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.8926 - acc: 0.6733\n",
            "Epoch 91/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.8785 - acc: 0.6711\n",
            "Epoch 92/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.8565 - acc: 0.6887\n",
            "Epoch 93/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.8331 - acc: 0.6909\n",
            "Epoch 94/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.8213 - acc: 0.6909\n",
            "Epoch 95/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.8029 - acc: 0.6843\n",
            "Epoch 96/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.7877 - acc: 0.6932\n",
            "Epoch 97/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.7778 - acc: 0.6932\n",
            "Epoch 98/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.7765 - acc: 0.7108\n",
            "Epoch 99/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.7383 - acc: 0.7174\n",
            "Epoch 100/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.7070 - acc: 0.7196\n",
            "Epoch 101/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.6993 - acc: 0.7241\n",
            "Epoch 102/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.6794 - acc: 0.7329\n",
            "Epoch 103/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.6520 - acc: 0.7307\n",
            "Epoch 104/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.6347 - acc: 0.7351\n",
            "Epoch 105/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.6105 - acc: 0.7373\n",
            "Epoch 106/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.6024 - acc: 0.7638\n",
            "Epoch 107/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.5976 - acc: 0.7329\n",
            "Epoch 108/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.5829 - acc: 0.7461\n",
            "Epoch 109/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.5628 - acc: 0.7572\n",
            "Epoch 110/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.5429 - acc: 0.7506\n",
            "Epoch 111/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.5251 - acc: 0.7594\n",
            "Epoch 112/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.5013 - acc: 0.7638\n",
            "Epoch 113/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.4816 - acc: 0.7616\n",
            "Epoch 114/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.4559 - acc: 0.7748\n",
            "Epoch 115/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.4423 - acc: 0.7792\n",
            "Epoch 116/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.4270 - acc: 0.7925\n",
            "Epoch 117/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.4142 - acc: 0.7881\n",
            "Epoch 118/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.3960 - acc: 0.7881\n",
            "Epoch 119/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.3821 - acc: 0.7947\n",
            "Epoch 120/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.3677 - acc: 0.8013\n",
            "Epoch 121/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.3603 - acc: 0.8013\n",
            "Epoch 122/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.3707 - acc: 0.7859\n",
            "Epoch 123/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.3642 - acc: 0.7859\n",
            "Epoch 124/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.3321 - acc: 0.7991\n",
            "Epoch 125/500\n",
            "453/453 [==============================] - 1s 2ms/sample - loss: 1.3119 - acc: 0.7925\n",
            "Epoch 126/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.2894 - acc: 0.8057\n",
            "Epoch 127/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.2697 - acc: 0.8190\n",
            "Epoch 128/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.2486 - acc: 0.8146\n",
            "Epoch 129/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.2358 - acc: 0.8146\n",
            "Epoch 130/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.2206 - acc: 0.8278\n",
            "Epoch 131/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.2040 - acc: 0.8322\n",
            "Epoch 132/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.1917 - acc: 0.8411\n",
            "Epoch 133/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.1858 - acc: 0.8433\n",
            "Epoch 134/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.1748 - acc: 0.8366\n",
            "Epoch 135/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.1580 - acc: 0.8411\n",
            "Epoch 136/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.1409 - acc: 0.8411\n",
            "Epoch 137/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.1448 - acc: 0.8344\n",
            "Epoch 138/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.1258 - acc: 0.8521\n",
            "Epoch 139/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.1132 - acc: 0.8433\n",
            "Epoch 140/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.1371 - acc: 0.8366\n",
            "Epoch 141/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.1325 - acc: 0.8344\n",
            "Epoch 142/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.1015 - acc: 0.8477\n",
            "Epoch 143/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.0777 - acc: 0.8499\n",
            "Epoch 144/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.0563 - acc: 0.8499\n",
            "Epoch 145/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.0456 - acc: 0.8631\n",
            "Epoch 146/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.0442 - acc: 0.8587\n",
            "Epoch 147/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.0492 - acc: 0.8499\n",
            "Epoch 148/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.0179 - acc: 0.8631\n",
            "Epoch 149/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.9996 - acc: 0.8587\n",
            "Epoch 150/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.9873 - acc: 0.8631\n",
            "Epoch 151/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.9743 - acc: 0.8675\n",
            "Epoch 152/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.9583 - acc: 0.8764\n",
            "Epoch 153/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.9472 - acc: 0.8830\n",
            "Epoch 154/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.9672 - acc: 0.8631\n",
            "Epoch 155/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.9829 - acc: 0.8543\n",
            "Epoch 156/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.9549 - acc: 0.8720\n",
            "Epoch 157/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.9452 - acc: 0.8609\n",
            "Epoch 158/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.9216 - acc: 0.8742\n",
            "Epoch 159/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.9417 - acc: 0.8742\n",
            "Epoch 160/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.9286 - acc: 0.8698\n",
            "Epoch 161/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.9008 - acc: 0.8808\n",
            "Epoch 162/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.8884 - acc: 0.8786\n",
            "Epoch 163/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.8750 - acc: 0.8918\n",
            "Epoch 164/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.8578 - acc: 0.8896\n",
            "Epoch 165/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.8469 - acc: 0.8940\n",
            "Epoch 166/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.8408 - acc: 0.8874\n",
            "Epoch 167/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.8288 - acc: 0.8962\n",
            "Epoch 168/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.8188 - acc: 0.8940\n",
            "Epoch 169/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.8035 - acc: 0.8962\n",
            "Epoch 170/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.7946 - acc: 0.8985\n",
            "Epoch 171/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.7883 - acc: 0.9029\n",
            "Epoch 172/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.7775 - acc: 0.9095\n",
            "Epoch 173/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.7699 - acc: 0.9095\n",
            "Epoch 174/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.7595 - acc: 0.9117\n",
            "Epoch 175/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.7495 - acc: 0.9095\n",
            "Epoch 176/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.7478 - acc: 0.9117\n",
            "Epoch 177/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.7401 - acc: 0.9117\n",
            "Epoch 178/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.7287 - acc: 0.9183\n",
            "Epoch 179/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.7212 - acc: 0.9205\n",
            "Epoch 180/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.7155 - acc: 0.9205\n",
            "Epoch 181/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.7083 - acc: 0.9249\n",
            "Epoch 182/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6998 - acc: 0.9249\n",
            "Epoch 183/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6905 - acc: 0.9272\n",
            "Epoch 184/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6833 - acc: 0.9294\n",
            "Epoch 185/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6743 - acc: 0.9272\n",
            "Epoch 186/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6736 - acc: 0.9249\n",
            "Epoch 187/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6628 - acc: 0.9272\n",
            "Epoch 188/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6582 - acc: 0.9227\n",
            "Epoch 189/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6499 - acc: 0.9227\n",
            "Epoch 190/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6417 - acc: 0.9316\n",
            "Epoch 191/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6339 - acc: 0.9316\n",
            "Epoch 192/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6264 - acc: 0.9338\n",
            "Epoch 193/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6236 - acc: 0.9294\n",
            "Epoch 194/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6146 - acc: 0.9316\n",
            "Epoch 195/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6134 - acc: 0.9338\n",
            "Epoch 196/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6035 - acc: 0.9338\n",
            "Epoch 197/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5958 - acc: 0.9360\n",
            "Epoch 198/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5919 - acc: 0.9338\n",
            "Epoch 199/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6005 - acc: 0.9294\n",
            "Epoch 200/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6116 - acc: 0.9294\n",
            "Epoch 201/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6176 - acc: 0.9272\n",
            "Epoch 202/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6047 - acc: 0.9249\n",
            "Epoch 203/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5923 - acc: 0.9338\n",
            "Epoch 204/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5751 - acc: 0.9404\n",
            "Epoch 205/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5647 - acc: 0.9404\n",
            "Epoch 206/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5657 - acc: 0.9404\n",
            "Epoch 207/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5507 - acc: 0.9426\n",
            "Epoch 208/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5442 - acc: 0.9404\n",
            "Epoch 209/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5329 - acc: 0.9426\n",
            "Epoch 210/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5278 - acc: 0.9426\n",
            "Epoch 211/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5224 - acc: 0.9426\n",
            "Epoch 212/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5153 - acc: 0.9404\n",
            "Epoch 213/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5126 - acc: 0.9426\n",
            "Epoch 214/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5065 - acc: 0.9426\n",
            "Epoch 215/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4999 - acc: 0.9404\n",
            "Epoch 216/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4963 - acc: 0.9426\n",
            "Epoch 217/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4906 - acc: 0.9448\n",
            "Epoch 218/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4855 - acc: 0.9448\n",
            "Epoch 219/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4819 - acc: 0.9448\n",
            "Epoch 220/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4780 - acc: 0.9448\n",
            "Epoch 221/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4764 - acc: 0.9448\n",
            "Epoch 222/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4731 - acc: 0.9448\n",
            "Epoch 223/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4684 - acc: 0.9470\n",
            "Epoch 224/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4592 - acc: 0.9426\n",
            "Epoch 225/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4576 - acc: 0.9426\n",
            "Epoch 226/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4559 - acc: 0.9448\n",
            "Epoch 227/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4517 - acc: 0.9448\n",
            "Epoch 228/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4451 - acc: 0.9426\n",
            "Epoch 229/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4439 - acc: 0.9426\n",
            "Epoch 230/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4387 - acc: 0.9404\n",
            "Epoch 231/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4324 - acc: 0.9470\n",
            "Epoch 232/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4280 - acc: 0.9470\n",
            "Epoch 233/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4236 - acc: 0.9426\n",
            "Epoch 234/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4186 - acc: 0.9426\n",
            "Epoch 235/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4150 - acc: 0.9448\n",
            "Epoch 236/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4121 - acc: 0.9448\n",
            "Epoch 237/500\n",
            "453/453 [==============================] - 1s 2ms/sample - loss: 0.4074 - acc: 0.9448\n",
            "Epoch 238/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4053 - acc: 0.9448\n",
            "Epoch 239/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3990 - acc: 0.9426\n",
            "Epoch 240/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3957 - acc: 0.9470\n",
            "Epoch 241/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3912 - acc: 0.9470\n",
            "Epoch 242/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3919 - acc: 0.9426\n",
            "Epoch 243/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3891 - acc: 0.9448\n",
            "Epoch 244/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3870 - acc: 0.9470\n",
            "Epoch 245/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3801 - acc: 0.9470\n",
            "Epoch 246/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3761 - acc: 0.9426\n",
            "Epoch 247/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3687 - acc: 0.9492\n",
            "Epoch 248/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3682 - acc: 0.9448\n",
            "Epoch 249/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3709 - acc: 0.9448\n",
            "Epoch 250/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3673 - acc: 0.9404\n",
            "Epoch 251/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3847 - acc: 0.9382\n",
            "Epoch 252/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3686 - acc: 0.9404\n",
            "Epoch 253/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3726 - acc: 0.9470\n",
            "Epoch 254/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3716 - acc: 0.9448\n",
            "Epoch 255/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3612 - acc: 0.9404\n",
            "Epoch 256/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4942 - acc: 0.9007\n",
            "Epoch 257/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5136 - acc: 0.9051\n",
            "Epoch 258/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4477 - acc: 0.9205\n",
            "Epoch 259/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4158 - acc: 0.9338\n",
            "Epoch 260/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3902 - acc: 0.9360\n",
            "Epoch 261/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3801 - acc: 0.9404\n",
            "Epoch 262/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3663 - acc: 0.9426\n",
            "Epoch 263/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3709 - acc: 0.9360\n",
            "Epoch 264/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3488 - acc: 0.9404\n",
            "Epoch 265/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3427 - acc: 0.9360\n",
            "Epoch 266/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3345 - acc: 0.9404\n",
            "Epoch 267/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3268 - acc: 0.9448\n",
            "Epoch 268/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3229 - acc: 0.9448\n",
            "Epoch 269/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3219 - acc: 0.9470\n",
            "Epoch 270/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3187 - acc: 0.9470\n",
            "Epoch 271/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3142 - acc: 0.9470\n",
            "Epoch 272/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3118 - acc: 0.9492\n",
            "Epoch 273/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3077 - acc: 0.9448\n",
            "Epoch 274/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3040 - acc: 0.9470\n",
            "Epoch 275/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3010 - acc: 0.9492\n",
            "Epoch 276/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3013 - acc: 0.9448\n",
            "Epoch 277/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2991 - acc: 0.9470\n",
            "Epoch 278/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2942 - acc: 0.9514\n",
            "Epoch 279/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2912 - acc: 0.9492\n",
            "Epoch 280/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2894 - acc: 0.9492\n",
            "Epoch 281/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2871 - acc: 0.9470\n",
            "Epoch 282/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2854 - acc: 0.9492\n",
            "Epoch 283/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2810 - acc: 0.9514\n",
            "Epoch 284/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2796 - acc: 0.9492\n",
            "Epoch 285/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2756 - acc: 0.9492\n",
            "Epoch 286/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2786 - acc: 0.9470\n",
            "Epoch 287/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2731 - acc: 0.9514\n",
            "Epoch 288/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2706 - acc: 0.9492\n",
            "Epoch 289/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2681 - acc: 0.9492\n",
            "Epoch 290/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2663 - acc: 0.9470\n",
            "Epoch 291/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2641 - acc: 0.9470\n",
            "Epoch 292/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2645 - acc: 0.9470\n",
            "Epoch 293/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2638 - acc: 0.9492\n",
            "Epoch 294/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2633 - acc: 0.9492\n",
            "Epoch 295/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2611 - acc: 0.9492\n",
            "Epoch 296/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2567 - acc: 0.9492\n",
            "Epoch 297/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2575 - acc: 0.9470\n",
            "Epoch 298/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2553 - acc: 0.9448\n",
            "Epoch 299/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2521 - acc: 0.9514\n",
            "Epoch 300/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2494 - acc: 0.9514\n",
            "Epoch 301/500\n",
            "453/453 [==============================] - 1s 2ms/sample - loss: 0.2474 - acc: 0.9514\n",
            "Epoch 302/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2463 - acc: 0.9492\n",
            "Epoch 303/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2445 - acc: 0.9492\n",
            "Epoch 304/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2417 - acc: 0.9492\n",
            "Epoch 305/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2424 - acc: 0.9470\n",
            "Epoch 306/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2427 - acc: 0.9492\n",
            "Epoch 307/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2386 - acc: 0.9514\n",
            "Epoch 308/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2523 - acc: 0.9470\n",
            "Epoch 309/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2893 - acc: 0.9360\n",
            "Epoch 310/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2764 - acc: 0.9448\n",
            "Epoch 311/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2679 - acc: 0.9426\n",
            "Epoch 312/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2713 - acc: 0.9426\n",
            "Epoch 313/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2619 - acc: 0.9448\n",
            "Epoch 314/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2546 - acc: 0.9426\n",
            "Epoch 315/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2495 - acc: 0.9470\n",
            "Epoch 316/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2476 - acc: 0.9492\n",
            "Epoch 317/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2447 - acc: 0.9492\n",
            "Epoch 318/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2351 - acc: 0.9492\n",
            "Epoch 319/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2373 - acc: 0.9470\n",
            "Epoch 320/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2295 - acc: 0.9492\n",
            "Epoch 321/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2273 - acc: 0.9514\n",
            "Epoch 322/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2269 - acc: 0.9514\n",
            "Epoch 323/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2242 - acc: 0.9492\n",
            "Epoch 324/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2236 - acc: 0.9470\n",
            "Epoch 325/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2206 - acc: 0.9448\n",
            "Epoch 326/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2203 - acc: 0.9492\n",
            "Epoch 327/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2181 - acc: 0.9514\n",
            "Epoch 328/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2157 - acc: 0.9448\n",
            "Epoch 329/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2141 - acc: 0.9448\n",
            "Epoch 330/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2140 - acc: 0.9492\n",
            "Epoch 331/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2105 - acc: 0.9470\n",
            "Epoch 332/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2095 - acc: 0.9470\n",
            "Epoch 333/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2080 - acc: 0.9470\n",
            "Epoch 334/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2074 - acc: 0.9470\n",
            "Epoch 335/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2059 - acc: 0.9514\n",
            "Epoch 336/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2052 - acc: 0.9470\n",
            "Epoch 337/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2039 - acc: 0.9470\n",
            "Epoch 338/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2023 - acc: 0.9492\n",
            "Epoch 339/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2011 - acc: 0.9492\n",
            "Epoch 340/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2020 - acc: 0.9448\n",
            "Epoch 341/500\n",
            "453/453 [==============================] - 1s 2ms/sample - loss: 0.1994 - acc: 0.9492\n",
            "Epoch 342/500\n",
            "453/453 [==============================] - 1s 2ms/sample - loss: 0.1981 - acc: 0.9514\n",
            "Epoch 343/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1968 - acc: 0.9514\n",
            "Epoch 344/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1961 - acc: 0.9492\n",
            "Epoch 345/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1949 - acc: 0.9470\n",
            "Epoch 346/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1945 - acc: 0.9470\n",
            "Epoch 347/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1932 - acc: 0.9514\n",
            "Epoch 348/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1913 - acc: 0.9492\n",
            "Epoch 349/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1908 - acc: 0.9492\n",
            "Epoch 350/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1897 - acc: 0.9514\n",
            "Epoch 351/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1884 - acc: 0.9492\n",
            "Epoch 352/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1872 - acc: 0.9514\n",
            "Epoch 353/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1858 - acc: 0.9492\n",
            "Epoch 354/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1854 - acc: 0.9514\n",
            "Epoch 355/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1842 - acc: 0.9514\n",
            "Epoch 356/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1834 - acc: 0.9470\n",
            "Epoch 357/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1841 - acc: 0.9514\n",
            "Epoch 358/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1822 - acc: 0.9448\n",
            "Epoch 359/500\n",
            "453/453 [==============================] - 1s 2ms/sample - loss: 0.1814 - acc: 0.9470\n",
            "Epoch 360/500\n",
            "453/453 [==============================] - 1s 2ms/sample - loss: 0.1801 - acc: 0.9492\n",
            "Epoch 361/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1793 - acc: 0.9492\n",
            "Epoch 362/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1780 - acc: 0.9448\n",
            "Epoch 363/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1784 - acc: 0.9448\n",
            "Epoch 364/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1782 - acc: 0.9492\n",
            "Epoch 365/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1763 - acc: 0.9470\n",
            "Epoch 366/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1787 - acc: 0.9448\n",
            "Epoch 367/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1786 - acc: 0.9470\n",
            "Epoch 368/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1755 - acc: 0.9514\n",
            "Epoch 369/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1736 - acc: 0.9470\n",
            "Epoch 370/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1728 - acc: 0.9514\n",
            "Epoch 371/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1720 - acc: 0.9492\n",
            "Epoch 372/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1722 - acc: 0.9514\n",
            "Epoch 373/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1707 - acc: 0.9470\n",
            "Epoch 374/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1701 - acc: 0.9536\n",
            "Epoch 375/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1693 - acc: 0.9492\n",
            "Epoch 376/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1679 - acc: 0.9470\n",
            "Epoch 377/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1669 - acc: 0.9448\n",
            "Epoch 378/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1662 - acc: 0.9448\n",
            "Epoch 379/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1660 - acc: 0.9514\n",
            "Epoch 380/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1648 - acc: 0.9536\n",
            "Epoch 381/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1640 - acc: 0.9492\n",
            "Epoch 382/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1635 - acc: 0.9470\n",
            "Epoch 383/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1626 - acc: 0.9492\n",
            "Epoch 384/500\n",
            "453/453 [==============================] - 1s 2ms/sample - loss: 0.1633 - acc: 0.9470\n",
            "Epoch 385/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1618 - acc: 0.9514\n",
            "Epoch 386/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1612 - acc: 0.9492\n",
            "Epoch 387/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1600 - acc: 0.9448\n",
            "Epoch 388/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1637 - acc: 0.9470\n",
            "Epoch 389/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1620 - acc: 0.9492\n",
            "Epoch 390/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1604 - acc: 0.9404\n",
            "Epoch 391/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1585 - acc: 0.9426\n",
            "Epoch 392/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1575 - acc: 0.9448\n",
            "Epoch 393/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1630 - acc: 0.9536\n",
            "Epoch 394/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1581 - acc: 0.9470\n",
            "Epoch 395/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1565 - acc: 0.9448\n",
            "Epoch 396/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1549 - acc: 0.9514\n",
            "Epoch 397/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1550 - acc: 0.9492\n",
            "Epoch 398/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1548 - acc: 0.9470\n",
            "Epoch 399/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1540 - acc: 0.9470\n",
            "Epoch 400/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1529 - acc: 0.9492\n",
            "Epoch 401/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1531 - acc: 0.9426\n",
            "Epoch 402/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1518 - acc: 0.9492\n",
            "Epoch 403/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1512 - acc: 0.9514\n",
            "Epoch 404/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1505 - acc: 0.9492\n",
            "Epoch 405/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1503 - acc: 0.9492\n",
            "Epoch 406/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1503 - acc: 0.9492\n",
            "Epoch 407/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1600 - acc: 0.9492\n",
            "Epoch 408/500\n",
            "453/453 [==============================] - 1s 2ms/sample - loss: 0.1551 - acc: 0.9470\n",
            "Epoch 409/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1512 - acc: 0.9470\n",
            "Epoch 410/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1485 - acc: 0.9492\n",
            "Epoch 411/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1476 - acc: 0.9426\n",
            "Epoch 412/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1468 - acc: 0.9492\n",
            "Epoch 413/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1470 - acc: 0.9492\n",
            "Epoch 414/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1467 - acc: 0.9448\n",
            "Epoch 415/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1456 - acc: 0.9470\n",
            "Epoch 416/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1454 - acc: 0.9404\n",
            "Epoch 417/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1451 - acc: 0.9492\n",
            "Epoch 418/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1439 - acc: 0.9492\n",
            "Epoch 419/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1468 - acc: 0.9448\n",
            "Epoch 420/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1445 - acc: 0.9514\n",
            "Epoch 421/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1439 - acc: 0.9492\n",
            "Epoch 422/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1436 - acc: 0.9426\n",
            "Epoch 423/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1428 - acc: 0.9492\n",
            "Epoch 424/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1423 - acc: 0.9514\n",
            "Epoch 425/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1422 - acc: 0.9492\n",
            "Epoch 426/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1413 - acc: 0.9492\n",
            "Epoch 427/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1400 - acc: 0.9492\n",
            "Epoch 428/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1399 - acc: 0.9470\n",
            "Epoch 429/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1400 - acc: 0.9470\n",
            "Epoch 430/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1410 - acc: 0.9492\n",
            "Epoch 431/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1407 - acc: 0.9492\n",
            "Epoch 432/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1407 - acc: 0.9492\n",
            "Epoch 433/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1390 - acc: 0.9536\n",
            "Epoch 434/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1373 - acc: 0.9536\n",
            "Epoch 435/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1371 - acc: 0.9470\n",
            "Epoch 436/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1365 - acc: 0.9470\n",
            "Epoch 437/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1359 - acc: 0.9492\n",
            "Epoch 438/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1349 - acc: 0.9514\n",
            "Epoch 439/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1348 - acc: 0.9514\n",
            "Epoch 440/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1346 - acc: 0.9426\n",
            "Epoch 441/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1343 - acc: 0.9492\n",
            "Epoch 442/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1347 - acc: 0.9492\n",
            "Epoch 443/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1340 - acc: 0.9470\n",
            "Epoch 444/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1337 - acc: 0.9448\n",
            "Epoch 445/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1343 - acc: 0.9448\n",
            "Epoch 446/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1338 - acc: 0.9470\n",
            "Epoch 447/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1320 - acc: 0.9514\n",
            "Epoch 448/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1320 - acc: 0.9470\n",
            "Epoch 449/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1312 - acc: 0.9492\n",
            "Epoch 450/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1310 - acc: 0.9448\n",
            "Epoch 451/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1304 - acc: 0.9470\n",
            "Epoch 452/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1307 - acc: 0.9514\n",
            "Epoch 453/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1311 - acc: 0.9426\n",
            "Epoch 454/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1333 - acc: 0.9514\n",
            "Epoch 455/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1331 - acc: 0.9492\n",
            "Epoch 456/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1303 - acc: 0.9492\n",
            "Epoch 457/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1292 - acc: 0.9492\n",
            "Epoch 458/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1290 - acc: 0.9470\n",
            "Epoch 459/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1280 - acc: 0.9492\n",
            "Epoch 460/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1276 - acc: 0.9470\n",
            "Epoch 461/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1287 - acc: 0.9426\n",
            "Epoch 462/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1270 - acc: 0.9514\n",
            "Epoch 463/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1275 - acc: 0.9470\n",
            "Epoch 464/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1275 - acc: 0.9448\n",
            "Epoch 465/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1264 - acc: 0.9470\n",
            "Epoch 466/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1268 - acc: 0.9470\n",
            "Epoch 467/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1267 - acc: 0.9448\n",
            "Epoch 468/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1259 - acc: 0.9448\n",
            "Epoch 469/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1254 - acc: 0.9514\n",
            "Epoch 470/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1247 - acc: 0.9492\n",
            "Epoch 471/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1246 - acc: 0.9426\n",
            "Epoch 472/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1239 - acc: 0.9448\n",
            "Epoch 473/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1252 - acc: 0.9470\n",
            "Epoch 474/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1270 - acc: 0.9470\n",
            "Epoch 475/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1283 - acc: 0.9492\n",
            "Epoch 476/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1439 - acc: 0.9448\n",
            "Epoch 477/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1475 - acc: 0.9448\n",
            "Epoch 478/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1449 - acc: 0.9426\n",
            "Epoch 479/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1361 - acc: 0.9470\n",
            "Epoch 480/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1348 - acc: 0.9514\n",
            "Epoch 481/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1540 - acc: 0.9382\n",
            "Epoch 482/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1815 - acc: 0.9404\n",
            "Epoch 483/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2634 - acc: 0.9161\n",
            "Epoch 484/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3394 - acc: 0.9051\n",
            "Epoch 485/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3149 - acc: 0.9029\n",
            "Epoch 486/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2665 - acc: 0.9183\n",
            "Epoch 487/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2134 - acc: 0.9360\n",
            "Epoch 488/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1966 - acc: 0.9338\n",
            "Epoch 489/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1787 - acc: 0.9316\n",
            "Epoch 490/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1597 - acc: 0.9404\n",
            "Epoch 491/500\n",
            "453/453 [==============================] - 1s 2ms/sample - loss: 0.1473 - acc: 0.9470\n",
            "Epoch 492/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1500 - acc: 0.9404\n",
            "Epoch 493/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1402 - acc: 0.9448\n",
            "Epoch 494/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1351 - acc: 0.9470\n",
            "Epoch 495/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1315 - acc: 0.9448\n",
            "Epoch 496/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1290 - acc: 0.9492\n",
            "Epoch 497/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1273 - acc: 0.9470\n",
            "Epoch 498/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1278 - acc: 0.9492\n",
            "Epoch 499/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1267 - acc: 0.9470\n",
            "Epoch 500/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1255 - acc: 0.9470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YXGelKThoTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poeprYK8h-c7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "7f298a27-7469-4b46-be51-ddbc11107793"
      },
      "source": [
        "plot_graphs(history, 'acc')\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Vc6PHgxa6Hm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5f6c1026-159d-420e-9538-6d53688c044e"
      },
      "source": [
        "seed_text = \"Laurence went to dublin\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = model.predict_classes(token_list, verbose=0)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Laurence went to dublin how the girls got they doing all ball entangled ball much i suppose suppose suppose suppose much i suppose suppose suppose suppose much i suppose suppose suppose suppose much i suppose suppose suppose suppose much i suppose suppose suppose suppose much i suppose suppose suppose suppose much i suppose suppose suppose suppose much i suppose suppose suppose suppose much i suppose suppose suppose suppose much i suppose suppose suppose suppose much i suppose suppose suppose suppose much i suppose suppose suppose suppose much i suppose suppose suppose suppose much i suppose suppose suppose suppose much i suppose suppose suppose suppose\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}